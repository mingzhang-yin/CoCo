{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case study \n",
    "# python version == 3.10.14\n",
    "# torch.__version__ == 2.2.2\n",
    "# numpy.__version__ == 1.26.4\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from torch import distributions as td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example1(e, m1, m2, N=10000): \n",
    "    #independent causes \n",
    "    beta = np.array([3.0, 2, 0])\n",
    "    x2_mean = m2\n",
    "    x2_e = torch.normal(x2_mean, e,[N,1])   \n",
    "    x1_mean = m1\n",
    "    x1_e = torch.normal(x1_mean, e,[N,1])\n",
    "    y_e = beta[0] * x1_e + beta[1] * x2_e + torch.randn(N,1)\n",
    "    z = e*y_e +  torch.normal(0, e, [N,1])\n",
    "    return (torch.cat((x1_e, x2_e, z), 1), y_e, beta)\n",
    "\n",
    "\n",
    "def IRMv1(environments, args, lmbd, init_random = False):\n",
    "    estimate_r = []\n",
    "    error_r = []\n",
    "    penalty_r = []\n",
    "    if init_random:\n",
    "        phi = torch.nn.Parameter(torch.normal(1,0.2,[environments[0][0].shape[1],1]))\n",
    "    else:\n",
    "        phi = torch.nn.Parameter(torch.Tensor([[3.0, 2.0, 0.0]]).T)\n",
    "    dummy_w = torch.nn.Parameter(torch.Tensor([1.0])) \n",
    "    opt1 = torch.optim.Adam([phi], lr=args.lrs) \n",
    "    phi_old = 0\n",
    "    for iteration in range(args.max_iter):\n",
    "        error = 0\n",
    "        penalty = 0\n",
    "        for i in range(len(environments)):\n",
    "            x_e, y_e, beta = environments[i]\n",
    "            error_e = 0.5*mse(x_e @ phi * dummy_w, y_e).mean()   \n",
    "            error += error_e\n",
    "            \n",
    "            phi_grad_out = torch.autograd.grad(error_e, dummy_w, create_graph=True)\n",
    "            penalty += torch.square(phi_grad_out[0]) \n",
    "  \n",
    "        opt1.zero_grad()\n",
    "        total_loss =  (error + lmbd * penalty)\n",
    "        total_loss.backward()     \n",
    "        opt1.step()\n",
    "        \n",
    "        estimate = phi.view(-1).detach().numpy()\n",
    "        estimate_r.append(estimate)\n",
    "        error_r.append(error.item())\n",
    "        penalty_r.append(penalty.item())\n",
    "        \n",
    "        if iteration % 2000 == 0: \n",
    "            phi_new = np.mean(estimate_r[-100:],axis=0)\n",
    "            print(phi_new)\n",
    "            if ((np.sum(np.abs(phi_new - phi_old))<0.001) & (iteration>=10000)):\n",
    "                break\n",
    "            else:\n",
    "                phi_old = phi_new\n",
    "    \n",
    "    return [np.mean(estimate_r[-100:],axis=0), np.mean(error_r[-100:]), np.mean(penalty_r[-100:])]\n",
    "\n",
    "\n",
    "\n",
    "def IRM_test(environments, coef):\n",
    "    phi = torch.nn.Parameter(torch.Tensor([coef])).T\n",
    "    dummy_w = torch.nn.Parameter(torch.Tensor([1.0])) \n",
    "    error = 0\n",
    "    penalty = 0\n",
    "    for i in range(len(environments)):\n",
    "        x_e, y_e, beta = environments[i]\n",
    "        error_e = 0.5*mse(x_e @ phi * dummy_w, y_e).mean()   \n",
    "        error += error_e\n",
    "        \n",
    "        phi_grad_out = torch.autograd.grad(error_e, dummy_w, create_graph=True)\n",
    "        pe1 = torch.square(phi_grad_out[0]) \n",
    "        penalty += pe1\n",
    "        \n",
    "        # phi_grad_out = torch.autograd.grad(error_e, phi,create_graph=True)\n",
    "        # pe2 = torch.square(torch.sum(phi_grad_out[0]*phi)) \n",
    "        # penalty += pe2\n",
    "     \n",
    "    return [error.item(), penalty.item()]\n",
    "\n",
    "\n",
    "def CoCo(environments, args):\n",
    "    estimate_r = []\n",
    "    phi = torch.nn.Parameter(torch.normal(1,0.2,[environments[0][0].shape[1],1]))\n",
    "    opt1 = torch.optim.Adam([phi], lr=args.lrs)  \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(opt1, step_size=2000, gamma=0.8)\n",
    "\n",
    "    phi_old = 0\n",
    "    for iteration in range(args.max_iter):\n",
    "        error = 0\n",
    "        penalty = 0\n",
    "        for i in range(len(environments)):\n",
    "            x_e, y_e, beta = environments[i]           \n",
    "            error_e = 0.5*mse(x_e @ phi, y_e).mean()  \n",
    "            error += error_e\n",
    "\n",
    "            phi_grad_out = torch.autograd.grad(error_e, phi,create_graph=True)\n",
    "            penalty += torch.square(phi_grad_out[0][0]) + \\\n",
    "                torch.sum(torch.square(phi_grad_out[0][1:]*phi[1:])) \n",
    "     \n",
    "        opt1.zero_grad()\n",
    "        total_loss =  torch.sqrt(penalty)\n",
    "        total_loss.backward()     \n",
    "        opt1.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        estimate = phi.view(-1).detach().numpy()\n",
    "        estimate_r.append(estimate)\n",
    "        if iteration % 2000 == 0: \n",
    "            phi_new = np.mean(estimate_r[-100:],axis=0)\n",
    "            print(phi_new)\n",
    "            if ((np.sum(np.abs(phi_new - phi_old))<0.001) & (iteration>=10000)):\n",
    "                break\n",
    "            else:\n",
    "                phi_old = phi_new  \n",
    "                          \n",
    "    return np.mean(estimate_r[-100:],axis=0)\n",
    "\n",
    "def ERM(environments, args):\n",
    "    estimate_r = []\n",
    "    phi = torch.nn.Parameter(torch.normal(1,0.2,[environments[0][0].shape[1],1]))\n",
    "    opt1 = torch.optim.SGD([phi], lr=0.002) \n",
    "    phi_old = 0\n",
    "    for iteration in range(args.max_iter):\n",
    "        error = 0\n",
    "        for i in range(len(environments)):\n",
    "            x_e, y_e, beta = environments[i]              \n",
    "            error_e = 0.5*mse(x_e @ phi , y_e).mean()  \n",
    "            error += error_e           \n",
    "        opt1.zero_grad()\n",
    "        error.backward()     \n",
    "        opt1.step()   \n",
    "        \n",
    "        estimate = phi.view(-1).detach().numpy()\n",
    "        estimate_r.append(estimate)\n",
    "        \n",
    "        if iteration % 2000 == 0:\n",
    "            phi_new = np.mean(estimate_r[-100:],axis=0)\n",
    "            print(phi_new)\n",
    "            if ((np.sum(np.abs(phi_new - phi_old))<0.001) & (iteration>=10000)):\n",
    "                break\n",
    "            else:\n",
    "                phi_old = phi_new                \n",
    "    return np.mean(estimate_r[-100:],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/m.yin/Library/Python/3.11/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6405374 0.7824335 0.5727433]\n",
      "[2.9818997  1.9819907  0.01841489]\n",
      "[2.990405   1.98872    0.01360961]\n",
      "[2.995853   1.994091   0.01003939]\n",
      "[2.9989142  1.9980304  0.00747031]\n",
      "[3.0002408  2.0010564  0.00559988]\n",
      "[3.0009122  2.0028532  0.00422782]\n",
      "[3.0018182  2.002843   0.00310581]\n",
      "[3.0012109e+00 2.0040286e+00 2.1859666e-03]\n",
      "[3.001315e+00 2.005207e+00 2.194642e-03]\n",
      "[3.0011315e+00 2.0037997e+00 9.3487598e-04]\n",
      "[3.0017123e+00 2.0044672e+00 1.4314966e-03]\n",
      "[3.0010374e+00 2.0038605e+00 5.4875284e-04]\n",
      "[3.0011694e+00 2.0038195e+00 5.3218758e-04]\n",
      "CoCo [3.0011694e+00 2.0038195e+00 5.3218758e-04]\n",
      "##############\n",
      "[1.0656513 1.088206  0.9634695]\n",
      "[-0.03507781  1.0945516   0.41847622]\n",
      "[-0.11566354  1.1363164   0.4240916 ]\n",
      "[-0.15687944  1.0552808   0.4357452 ]\n",
      "[-0.2579613   0.85396653  0.46408054]\n",
      "[-0.4652736   0.42912257  0.5210888 ]\n",
      "[-0.7320835  -0.14375661  0.592129  ]\n",
      "[-0.83901703 -0.38267514  0.6197817 ]\n",
      "[-0.84236217 -0.390255    0.62064666]\n",
      "[-0.8424558  -0.39035785  0.62056047]\n",
      "IRMv1 [array([-0.8424558 , -0.39035785,  0.62056047], dtype=float32), 26.839935760498047, 0.28308060079813]\n",
      "[3.01 2.01 0.01]\n",
      "[2.9321702  1.8475356  0.01753434]\n",
      "[2.9321563  1.8475033  0.01753751]\n",
      "[2.9319143  1.8472599  0.01729486]\n",
      "[2.932156   1.8475033  0.01753796]\n",
      "[2.9321487  1.8474888  0.01754105]\n",
      "IRMv1 [array([2.9321487 , 1.8474888 , 0.01754105], dtype=float32), 0.9763650023937225, 0.0032880650309380145]\n",
      "##############\n",
      "IRM_test [0.9985232353210449, 0.0003584923397284001]\n",
      "##############\n",
      "[1.1088216  1.2382995  0.39400446]\n",
      "[2.8030672 1.7609613 0.0461349]\n",
      "[2.815521   1.7784066  0.04347659]\n",
      "[2.8156767  1.7786363  0.04344223]\n",
      "[2.8156767  1.7786363  0.04344223]\n",
      "[2.8156767  1.7786363  0.04344223]\n",
      "ERM [2.8156767  1.7786363  0.04344223]\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=2, help='Random seed')\n",
    "parser.add_argument('--max_iter', type=int, default=100000, help='max iteration.')\n",
    "parser.add_argument('--N', type=int, default=100000, help='number of data per env.')\n",
    "parser.add_argument('--path', default='results/', help='The path results to be saved.')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "mse = torch.nn.MSELoss(reduction=\"none\")  \n",
    "environments = [example1(0.5, 3, -1, N=args.N), \n",
    "            example1(2, 2, 0.5, N=args.N)]  \n",
    "\n",
    "args.lrs = 0.3\n",
    "print('##############')\n",
    "print('CoCo', CoCo(environments, args))\n",
    "print('##############')\n",
    "args.lrs = 0.01\n",
    "result = IRMv1(environments, args, lmbd=1, init_random=True)\n",
    "print('IRMv1', result)\n",
    "result = IRMv1(environments, args, lmbd=1, init_random=False)\n",
    "print('IRMv1', result)\n",
    "print('##############')\n",
    "print('IRM_test', IRM_test(environments, [3,2,0]))\n",
    "print('##############')\n",
    "print('ERM', ERM(environments, args))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
